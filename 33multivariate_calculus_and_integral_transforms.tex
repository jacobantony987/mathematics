%Text Books : \cite{apostol}, \cite{rudin}
%Module 1:
%The Weirstrass theorem, other forms of Fourier series, the Fourier integral theorem, the exponential form of the Fourier integral theorem, integral transforms and convolutions, the convolution theorem for Fourier transforms.
%(Chapter 11 Sections 11.15 to 11.21 of \cite{apostol}) (20 hours.)
%Module 2:
%Multivariable Differential Calculus, The directional derivative, directional derivatives and continuity, the total derivative, the total derivative expressed in terms of partial derivatives, An application of complex- valued functions, the matrix of a linear function, the Jacobian matrix, the matrix form of the chain rule. Implicit functions and extremum problems, the mean value theorem for differentiable functions,
%(Chapter 12 Sections. 12.1 to 12.11 of \cite{apostol}) (22 hours.)
%Module 3: 
%A sufficient condition for differentiability, a sufficient condition for equality of mixed partial derivatives, functions with non-zero Jacobian determinant, the inverse function theorem ,the implicit function theorem, extrema of real- valued functions of one variable, extrema of real-valued functions of several variables.
%Chapter 12 Sections-. 12.12 to 12.13 of \cite{apostol} 
%Chapter 13 Sections-. 13.1 to 13.6 of \cite{apostol} (28 hours.)
%Module 4:
%Integration of Differential Forms Integration, primitive mappings, partitions of unity, change of variables, differential forms.
%(Chapter 10 Sections. 10.1 to 10.14 of \cite{rudin}) (20 hours)

\part{ME010303 Multivariate Calculus \& Integral Transforms}
%Module 1 - \cite{apostol} 11
%Module 2 - \cite{apostol} 12
%Module 3 - \cite{apostol} 12, 13
%Module 4 - \cite{rudin} 10
%\cite{apostol}
%\chapter{The Real and Complex Number Systems*}
%\chapter{Some Basic Notations of Set Theory*}
%\chapter{Elements of Point Set Topology*}
%\chapter{Limits and Continuity*}
%\chapter{Derivatives*}
%\chapter{Functions of Bounded Variation and Rectifiable Curves*}
%\chapter{The Riemann-Stieltjes Integral*}
%\chapter{Infinite Series adn Infinite Products*}
%\chapter{Sequences of Functions*}
%\chapter{The Lebesgue Integral*}
\chapter{Fourier Series and Fourier Integrals}
\section{The Weierstrass Approximation Theorem}
	Every continuous, real valued function on a compact interval has a polynomial approximation.\cite[Theorem 11.17]{apostol}
	\begin{theorem}[Weierstrass]
		Let $f$ be a real-valued, continuous function on a compact interval $[a,b]$. Then for every \(\epsilon > 0\), there is a polynomial $p$ such that \(|f(x)-p(x)| < \epsilon\) for every \(x \in [a,b]\).
	\end{theorem}
	\begin{synopsis}
		Given a real-valued continuous function on compact interval $[a,b]$, we can construct a real-valued, continous function $g$ on $\mathbb{R}$ which is periodic with period $2\pi$. We have, if \(f \in L(I)\) and $f$ is bounded almost everywhere in $I$, then \(f \in L^2(I)\).\cite[Theorem 10.52]{apostol}.By Fejer's theorem (\cite[Theorem 11.15]{apostol}), the fourier series generated by $g$ (\cite[definition 11.3]{apostol}) converges to the Cesaro sum (\cite[Definition 8.47]{apostol}), which is $g$ itself in this case. Thus for any \(\epsilon > 0\), there is a finite sum of trignometric functions. The power series expansions of trignometric functions (\cite[definition 9.27]{apostol}) being uniformly convergent, there exists a polynomial $p_m$ which approximates $g$. And we can construct $p$ (polynomial approximation of $g$) using $p_m$.
	\end{synopsis}
	\begin{proof}
		Define \(g : \mathbb{R} \to \mathbb{R}\),
		\[ g(t) = \begin{cases}
			f(a+(b-a)t/\pi),\ t \in [0,\pi) \\
			f(a+(2\pi-t)(b-a)/\pi),\ t \in [\pi,2\pi] \\
			g(t - 2n\pi),\ t > 2\pi,\ n \in \mathbb{N} \\
			g(t+2n\pi),\ t < 0,\ n \in \mathbb{N}
			\end{cases}\]

		Thus $g$ is a continuous, real-valued, periodic function with period $2\pi$ such that
		\begin{equation}
			f(x) = g\left(\frac{\pi (x-a)}{b-a}\right),\ x \in [a,b]
			\label{equ:fx}
		\end{equation}

		The fourier series generated by $g$ is given by,
		\[ g(t) \sim \frac{a_0}{2} + \sum_{k=1}^\infty \left( a_k \cos kt + b_k \sin kt \right)\]
		\[ \text{ where } a_k = \frac{1}{\pi} \int_0^{2\pi} f(t) \cos kt\ dt,\ b_k = \frac{1}{\pi} \int_0^{2\pi} f(t) \sin kt\ dt\]

		Let \(\sequence{s_n(t)}\) be the sequence of partial sums of the fourier series generated by $g$. And \( \sequence{\sigma_n(t)}\)  be the sequence of averages of $s_n(t)$ given by,
		\[\sigma_n(t) = \frac{1}{n} \sum_{k = 1}^n s_k(t),\text{ where } s_k(t) = \frac{a_0}{2} + \sum_{j = 1}^k \left( a_j \cos jt + b_j \sin jt \right)\]

		Function \(f \in L(I)\) being real-valued continuous function on a compact interval, it is bounded and hence is Lebesgue square integrable.ie, \(f \in L^2(I)\). Thus, \(g \in L^2(I)\).\\

		Since $g$ is continous on $\mathbb{R}$, the function \(s : \mathbb{R} \to \mathbb{R}\) defined by,
		\[ s(t) = \lim_{h \to 0^+} \frac{g(t+h)-g(t-h)}{2} \]
		is well-defined on $\mathbb{R}$ and \(s(t) = g(t),\ \forall t \in \mathbb{R}\).\\

		Then by Fejer's Theorem, the sequence \(\sequence{\sigma_n(t)}\) converges uniformly to $g(t)$ for every \(t \in \mathbb{R}\). Thus, given \(\epsilon > 0\), there exists \(N \in \mathbb{N}\) such that \(\forall t \in \mathbb{R}\), \(|g(t)-\sigma_N(t)| < \frac{\epsilon}{2}\).\\

		We have,
		\begin{equation}
			\sigma_N(t) = \sum_{k=0}^N \left(A_k \cos kt + B_k \sin kt \right),\text{ where } A_k, B_k \in \mathbb{R}
			\label{equ:sigmaN}
		\end{equation}
		By the power series expansion of the trignometric functions about origin,
		\begin{equation}
			\cos kt = \sum_{j = 1}^\infty \left(\frac{\cos^{(j)} 0}{j!} (kt)^j \right)  = \sum_{j = 1}^\infty A_j' t^j \text{ where } A_j' \in \mathbb{R}
			\label{equ:coskt}
		\end{equation}
		\begin{equation}
			\sin kt = \sum_{j = 1}^\infty \left(\frac{\sin^{(j)} 0}{j!} (kt)^j \right)  = \sum_{j = 1}^\infty B_j' t^j \text{ where } B_j' \in \mathbb{R}
			\label{equ:sinkt}
		\end{equation}

		Since the above power series expansions of trignometric functions are uniformly convergent, their finite linear combination \(\sequence{\sigma_N(t)}\) is also uniformly convergent. ie, Given \(\epsilon > 0\) there exists \(m \in \mathbb{N}\) such that for every \(t \in \mathbb{R}\)
		\[\left|\sum_{k = 0}^m C_k t^k - \sigma_N(t)\right| < \frac{\epsilon}{2} \text{ where } C_k \in \mathbb{R}\]

		Therefore, \(| p_m(t) - g(t)| \le | p_m(t) - \sigma_N(t) | + |\sigma_N(t) - g(t)| < \epsilon\) where \(p_m(t) = \sum_{k = 0}^m C_k t^k\). Define \(p : [a,b] \to \mathbb{R}\) by,
		\begin{equation}
			p(x) = p_m\left( \frac{\pi(x-a)}{b-a} \right)
			\label{equ:px}
		\end{equation}

		By equations \ref{equ:fx} and \ref{equ:px}, \(|p(x)-f(x)| < \epsilon\) for every \(x \in [a,b]\).
	\end{proof}
\section{Other Forms of Fourier Series}
	Let \(f \in L([0,2\pi])\), then the fourier series generated by $f$ is given by,
	\[ f(x) \sim \frac{a_0}{2}+\sum_{n=1}^\infty \left( a_n \cos nx + b_n \sin nx \right) \]
	\[ \text{ where } a_n = \frac{1}{\pi} \int_0^{2\pi} f(t) \cos nt\ dt,\qquad b_n = \frac{1}{\pi} \int_0^{2\pi} f(t) \sin nt\ dt \]

	By Euler's forumula \(e^{inx} = \cos nx + i\sin nx\). We have, \(\cos nx = \frac{(e^{inx}+e^{-inx})}{2}\) and \(\sin nx = \frac{(e^{inx}-e^{-inx})}{2i}\)

	\[ f(x) \sim \frac{a_0}{2} + \sum_{n=1}^\infty \left( \alpha_n e^{inx} + \beta_n e^{-inx} \right) \]

	\[ \text{ where } \alpha_n = \frac{(a_n - ib_n)}{2} \qquad \beta_n = \frac{(a_n+ib_n)}{2} \]

	Therefore, by assigning \(\alpha_0 = a_0/2\), \(\alpha_{-n} = \beta_n\), we get the following exponential form of fourier series generated by $f$,

	\[ f(x) \sim \sum_{n = -\infty}^\infty \alpha_n e^{inx} \text{ where } \alpha_n = \frac{1}{2\pi} \int_0^{2\pi} f(t)\ e^{-int}\ dt \]

	Note : If $f$ is periodic with period $2\pi$, then the interval of integration $[0,2\pi]$ can be replaced with any interval of length $2\pi$. eg. $[-\pi,\pi]$

\subsection{Periodic with period $p$}
	Let \(f \in L([0,p])\) and $f$ is periodic with period $p$. Then
	\[ f(x) \sim \frac{a_0}{2} + \sum_{n=1}^\infty \left( a_n \cos \frac{2\pi nx}{p} + b_n \sin \frac{2\pi nx}{p} \right) \]
	\[ \text{ where } a_n = \frac{2}{p} \int_0^p f(t) \cos \frac{2\pi nt}{p}\ dt \qquad b_n = \frac{2}{p} \int_0^p f(t) \sin \frac{2\pi nt}{p}\ dt \]
	Therefore, we have the exponential form of the above fourier series given by,
	\[ f(x) \sim \sum_{n = -\infty}^\infty \alpha_n e^\frac{2\pi inx}{p},\text{ where } \alpha_n = \frac{1}{p} \int_0^p f(t)\ e^\frac{-2\pi int}{p}\ dt \]
	
\section{Fourier Integral Theorem}

\begin{theorem}[Fourier Integral Theorem]
	Let \(f \in L(-\infty,\infty)\). Suppose \(x \in \mathbb{R}\) and an interval $[x-\delta,x+\delta]$ about $x$ such that either 
	\begin{enumerate}
		\item $f$ is of bounded variation on an interval $[x-\delta,x+\delta]$ about $x$ or
		\item both limits $f(x+)$ and $f(x-)$ exists and both Lebesgue intergrals
			\[ \int_0^\delta \frac{f(x+t)-f(x+)}{t} dt \text{ and }\int_0^\delta \frac{f(x-t)-f(x-)}{t} dt \]
			exists.
	\end{enumerate}
	Then, 
	\[ \frac{f(x+)+f(x-)}{2} = \frac{1}{\pi} \int_0^\infty \int_{-\infty}^\infty f(u)\cos v(u-x)\ du\ dv, \]
	the integral $\int_0^\infty$ being an improper Riemann integral.
\end{theorem}
\begin{synopsis}
	\[ f(x+t)\frac{\sin \alpha t}{\pi t} dt \to f(u)\frac{\sin \alpha(u-x)}{\pi(u-x)} \to \frac{f(u)}{\pi} \int_0^\alpha \cos v(u-x) dv \]
	By Riemann-Lebesgue lemma\cite[Theorem 11.6]{apostol},
	\[ f \in L(I) \implies \lim_{\alpha \to +\infty} \int_I f(x) \sin \alpha t\ dt = 0 \]
	By Jordan's Theorem\cite[Theorem 10.8]{apostol}, if $g$ is of bounded variation on $[0,\delta]$, then
	\[ \lim_{\alpha \to +\infty} \frac{2}{\pi} \int_0^\delta g(t) \frac{\sin \alpha t}{t} dt = g(0+) \]
	By Dini's Theorem\cite[Theorem 10.9]{apostol}, if the limit $g(x+)$ exists and Lebesgue integral \( \int_0^\delta \frac{g(t)+g(0+)}{t} dt \) exists for some \( \delta > 0 \), then
	\[ \lim_{\alpha to +\infty} \frac{2}{\pi} \int_0^\delta g(t) \frac{\sin \alpha t}{t} dt = g(0+) \]
	The order of Lebesgue integrals can be interchanged\cite[Theorem 10.40]{apostol},\\
	Suppose \(f \in L(X)\) and \(g \in L(Y)\).Then
	\[ \int_X f(x) \left(\int_Y g(y) k(x,y) dy \right) dx = \int_Y g(y) \left( \int_X f(x) k(x,y) dx \right) dy \]
\end{synopsis}
\begin{proof}
	Consider \( \int_{-\infty}^\infty f(x+t) \frac{\sin \alpha t}{\pi t} dt \). We prove that this integral is equal to the either sides.
	\[ \int_{-\infty}^\infty f(x+t) \frac{\sin \alpha t}{\pi t} dt = \int_{-\infty}^{-\delta} + \int_{-\delta}^0 + \int_0^{-\delta}  + \int_{\delta}^\infty f(x+t) \frac{\sin \alpha t}{\pi t} dt \] 
	We have, function \( \frac{f(x+t)}{\pi t} \) is bounded on \( (-\infty,-\delta)\cup(\delta,\infty) \), hence \( \frac{f(x+t)}{\pi t} \) is Lebesgue integrable on \( (-\infty,-\delta) \cup (\delta,\infty) \).\\
	
	By Riemann Lebesgue lemma, 
	\[ \frac{f(x+t)}{\pi t} \in L(-\infty,-\delta) \implies \int_{-\infty}^{-\delta} f(x+t) \frac{\sin \alpha t}{\pi t} dt = 0, \]
	\[ \frac{f(x+t)}{\pi t} \in L(\delta,\infty) \implies \int_{\delta}^{\infty} f(x+t) \frac{\sin \alpha t}{\pi t} dt = 0 \]

	\paragraph{Case 1}
	Suppose $f$ is of bounded variation on $[x-\delta,x+\delta]$, put \( g(t) = f(x+t) \) then $g$ is of bounded variation on $[-\delta,\delta]$. Thus $g$ is of bounded variation on $[0,\delta]$. Then by Jordan's Theorem
	\[ \lim_{\alpha \to +\infty} \frac{2}{\pi}\int_0^\delta f(x+t)\frac{\sin \alpha t}{t} dt = \lim_{\alpha \to +\infty} \frac{2}{\pi} \int_0^\delta g(t) \frac{\sin \alpha t}{t} dt = g(0+) = f(x+) \]

	\paragraph{Case 2}
	Suppose both the limits $f(x+)$ and $f(x-)$ exists and both Lebesgue integrals
	\[ \int_0^\delta \frac{f(x+t)-f(x+)}{t} dt \text{ and } \int_0^\delta \frac{f(x-t)-f(x-)}{t} dt \]
	exists.\\

	Thus, we have $f(x+)$ exists and the Lebesgue integral \( \int_0^\delta \frac{f(x+t)-f(x+)}{t} dt \) exists. Put \( g(t) = f(x+t) \), then \( g(0+) = f(x+) \) exists and the Lebesgue integral \( \int_0^\delta \frac{g(t)-g(0+)}{t} dt \) exists, then by Dini's Theorem,
	\[ \lim_{\alpha \to +\infty} \frac{2}{\pi}\int_0^\delta f(x+t)\frac{\sin \alpha t}{t} dt = \lim_{\alpha \to +\infty} \frac{2}{\pi} \int_0^\delta g(t) \frac{\sin \alpha t}{t} dt = g(0+) = f(x+) \]

	Similarly, $f(x-)$ exists and the Lebesgue integral \( \int_0^\delta \frac{f(x-t)-f(x-)}{t} dt \) exists. Put \( g(t) = f(x-t) \), then \( g(0+) = f(x-) \) exists and the Lebesgue integral \( \int_0^\delta \frac{g(t)-g(0+)}{t} dt \) exists, then by Dini's Theorem,
	\begin{align*}
		\lim_{\alpha \to +\infty} \frac{2}{\pi}\int_{-\delta}^0 f(x+t)\frac{\sin \alpha t}{t} dt
		& = \lim_{\alpha \to +\infty} \frac{2}{\pi} \int_0^\delta f(x-\tau) \frac{\sin \alpha \tau}{\tau} d\tau\\
		& = \lim_{\alpha \to +\infty} \frac{2}{\pi} \int_0^\delta g(\tau) \frac{\sin \alpha \tau}{\tau} d\tau = g(0+) = f(x-)
	\end{align*}

	Then by either cases,
	\begin{align*}
		\lim_{\alpha \to +\infty} \int_{-\infty}^\infty f(x+t) \frac{\sin \alpha t}{\pi t} dt 
		& = \lim_{\alpha \to +\infty} \int_{-\delta}^0 + \int_0^\delta f(x+t) \frac{\sin \alpha t}{\pi t} dt \\
		& = \frac{f(x+)+f(x-)}{2}
	\end{align*}

	We have, \( \int_0^\alpha \cos v(u-x) dv = \frac{\sin v(u-x)}{u-x} \).
	\begin{align*}
		\lim_{\alpha \to +\infty} \int_{-\infty}^\infty f(x) \frac{ \sin \alpha t}{\pi t} dt 
		& = \lim_{\alpha \to +\infty} \int_{-\infty}^\infty f(u) \frac{ \sin \alpha (u-x)}{u-x} du,\ (\text{put }u = x+t)\\
		& = \lim_{\alpha \to +\infty} \int_{-\infty}^\infty f(u) \left( \int_0^\alpha \cos v(u-x) dv \right) du\\
		& = \lim_{\alpha \to +\infty} \int_0^\alpha \left( \int_{-\infty}^\infty f(u) \cos v(u-x) du \right) dv,\\
		& \text{since, the order of Lebesgue integrals can be reversed.}\\
		& = \int_0^\infty \left( \int_{-\infty}^\infty f(u) \cos v(u-x) du \right) dv\\
		\text{where, } \int_0^\infty \text{ is not }& \text{a Lebesgue integral, but an improper Riemann integral }
	\end{align*}
	Therefore,
	\begin{align*}
		\int_0^\infty \left( \int_{-\infty}^\infty f(u) \cos v(u-x) du \right) dv
		& = \lim_{\alpha \to +\infty} \int_{-\infty}^\infty f(x) \frac{ \sin \alpha t}{\pi t} dt \\
		& =  \frac{f(x+)+f(x-)}{2}
	\end{align*}
\end{proof}

\begin{remark}
	If a function $f$ on $(-\infty,\infty)$ is non-periodic, then it may not have a fourier series represenation. In such cases, we have fourier intergral representaion.
\end{remark}

\section{Exponential form of Fourier Integral Theorem}
	Let \( f \in L(-\infty,\infty) \). Suppose \( x \in \mathbb{R} \) and an interval $[x-\delta,x+\delta]$ about $x$ such that either 
	\begin{enumerate}
		\item $f$ is of bounded variation on an interval $[x-\delta,x+\delta]$ about $x$ or
		\item both limits $f(x+)$ and $f(x-)$ exists and both Lebesgue intergrals
			\[ \int_0^\delta \frac{f(x+t)-f(x+)}{t} dt \text{ and }\int_0^\delta \frac{f(x-t)-f(x-)}{t} dt \]
			exists.
	\end{enumerate}
	Then, 
	\[ \frac{f(x+)+f(x-)}{2} = \lim_{\alpha \to \infty} \frac{1}{2\pi} \int_{-\alpha}^\alpha \left( \int_{-\infty}^\infty f(u) e^{iv(u-x)}\ du\right) dv \]
	\begin{proof}
		Let \( F(v) = \int_{-\infty}^\infty f(u) \cos v(u-x) du \). Then \( F(v) = F(-v) \) and 
		\begin{align*}
			\lim_{\alpha \to \infty} \frac{1}{2\pi} \int_{-\alpha}^\alpha F(v) dv
			& = \lim_{\alpha \to \infty} \frac{1}{\pi} \int_0^\alpha \int_{-\infty}^\infty f(u) \cos v(u-x) du dv\\
			& = \frac{f(x+)+f(x-)}{2}
		\end{align*}
		Let \( G(v) = \int_{-\infty}^\infty f(u) \sin v(u-x) du \). Then \( G(v) = -G(-v) \) and
		\[ \lim_{\alpha \to \infty} \frac{1}{2\pi} \int_{-\alpha}^\alpha G(v) dv = 0 \]
		Thus 
		\[ \lim_{\alpha \to \infty} \frac{1}{2\pi} \int_{-\alpha}^\alpha F(v) + iG(v) dv = \frac{f(x+)+f(x-)}{2} \]
	\end{proof}

\section{Integral Transforms}
\begin{definition}
	Integral transform $g(y)$ of $f(x)$ is a Lebesgue integral or Improper Riemann integral of the form
	\[ g(y) = \int_{-\infty}^\infty K(x,y) f(x)\ dx \], where $K$ is the kernal of the transform. We write \( g = \mathscr{K}(f) \).
\end{definition}

\begin{remark}
	Integral transforms(operators) are linear operators.\\
	 ie, \( \mathscr{K}(af_1 + bf_2) = a\mathscr{K}f_1 + b\mathscr{K}f_2 \)
\end{remark}

\begin{remark} A few commonly used integral transforms,
\begin{enumerate}
	\item Exponential Fourier Transform $\mathscr{F}$,
		\[ \mathscr{F}f = \int_{-\infty}^\infty e^{-ixy}f(x)\ dx \]
	\item Fourier Cosine Transform $\mathscr{C}$,
		\[ \mathscr{C}f = \int_0^\infty \cos xy f(x)\ dx \]
	\item Fourier Sine Transform $\mathscr{S}$,
		\[ \mathscr{S}f = \int_0^\infty \sin xy f(x)\ dx \]
	\item Laplace Transform $\mathscr{L}$,
		\[ \mathscr{L}f = \int_0^\infty e^{-xy} f(x)\ dx \]
	\item Mellin Transform $\mathscr{M}$,
		\[ \mathscr{M}f = \int_0^\infty x^{y-1}f(x)\ dx \]
\end{enumerate}
\end{remark}

\begin{remark} Suppose \( f(x) = 0,\ \forall x < 0 \).
	\[ \int_{-\infty}^\infty e^{-ixy}f(x)\ dx = \int_0^\infty e^{-ixy}f(x)\ dx = \int_0^\infty \cos xy \ f(x)\ dx + i \int_0^\infty \sin xy \ f(x)\ dx \]
	\[ \mathscr{F}f = \mathscr{C}f + i\mathscr{S}f \]\\
	Therefore Fourier Cosine $\mathscr{C}$ and Sine $\mathscr{S}$ transforms are special cases of fourier integral transform, $\mathscr{F}$ provided $f$ vanishes on negative real axis.
\end{remark}

\begin{remark} Let \( y = u+iv \), \( f(x) = 0,\ \forall x < 0 \).
	\[ \int_0^\infty e^{-xy}f(x) = \int_0^\infty e^{-xu}e^{-ixv}f(x)\ dx = \int_0^\infty e^{-ixv} \phi_u(x) dx \]
	where \( \phi_u(x) = e^{-xu}f(x) \).
	\[ \mathscr{L}f = \mathscr{F}\phi_u \]
	Therefore Laplace transform, $\mathscr{L}$ is a special case of Fourier integral transform, $\mathscr{F}$.
\end{remark}

\begin{remark} Let \( g(y) = \mathscr{F}f(x) \).
	\[ g(y) = \int_{-\infty}^\infty e^{-ixy}f(x)\ dx \]
	Suppose $f$ is continuous at $x$, then by fourier integral theorem,
	\begin{align*}
		f(x)	& = \frac{1}{2\pi} \int_{-\infty}^\infty \left( \int_{-\infty}^\infty f(u) e^{iv(u-x)} du \right) dv\\
			& = \int_{-\infty}^\infty e^{-ivx} \left( \frac{1}{2\pi} \int_{-\infty}^\infty e^{ivu} f(u)\ du \right) dv\\
			& = \int_{-\infty}^\infty g(v) e^{-ivx} dv = \mathscr{F}g \text{ where } g(v) = \frac{1}{2\pi}\int_{-\infty}^\infty f(u) e^{ivu} du 
	\end{align*}
	The above function $g(v)$ gives the \textbf{inverse fourier transformation} of $f$.\\

	Let $g$ be fourier transform of $f$, then $f$ is uniquely determined by its fourier transform $g$ by,
	\[ f(x) = \mathscr{F}^{-1}g(y) = \frac{1}{2\pi} \lim_{\alpha \to \infty} \int_{-\alpha}^\alpha g(y) e^{ixy} dy \]
\end{remark}

\begin{enumerate}
	\setcounter{enumi}{5}
	\item Inverse Fourier Transform $\mathscr{F}^{-1}$,
		\[ \mathscr{F}^{-1}f = \int_{-\infty}^\infty \frac{e^{ixy}}{2\pi}f(x)\ dx \]
\end{enumerate}

\section{Convolutions}
\begin{definition}
	Let \( f,g \in L(-\infty,\infty) \). Let $S$ be the set of all points $x$ for which the Lebesgue integral
	\[ h(x) = \int_{-\infty}^\infty f(t) g(x-t) dt \]
	exists. Then the function \( h : S \to \mathbb{R} \) is a convolution of $f$ and $g$. And \( h = f \ast g \).
\end{definition}

\begin{remark}
	Convolution operator is commutative.\\
	ie, \( h = f \ast g = g \ast f \)
\end{remark}

\begin{remark}
	Suppose $f,g$ vanishes on negative real axis, then
	\[ h(x) = \int_{-\infty}^\infty f(t)\ g(x-t)\ dt = \int_{-\infty}^0 + \int_0^x  + \int_x^\infty f(t)\ g(x-t)\ dt = \int_0^x f(t)\ g(x-t)\ dt \] 
\end{remark}

\begin{remark}
	Singularity is a point at which the convolution integral fails to exists.
\end{remark}

\begin{theorem}
	Let \( f,g \in L(\mathbb{R}) \) and either $f$ or $g$ is bounded in $\mathbb{R}$. Then the convoluton integral
	\[ h(x) = \int_{-\infty}^\infty f(t) g(x-t) dt \]
	exists for every \( x \in \mathbb{R} \) and the function $h$ so defined is bouned in $\mathbb{R}$. In addition, if the bounded function is continuous on $\mathbb{R}$, then $h$ is continuous and \( h \in L(\mathbb{R}) \).
\end{theorem}
\begin{synopsis}
\end{synopsis}
\begin{proof}
\end{proof}

\begin{remark}
	If $f,g$ are both unbounded, the convolution integral may not exist.
	\[ \text{ eg: } f(t) = \frac{1}{\sqrt{t}},\ g(t) = \frac{1}{\sqrt{1-t}} \]
\end{remark}

\begin{theorem}
	Let \( f,g \in L^2(\mathbb{R}) \). Then the convolution integral $f \ast g$ exists for each \( x \in \mathbb{R} \) and the function \( h : \mathbb{R} \to \mathbb{R} \) defined by \( h(x) = f \ast g (x) \) is bounded in $\mathbb{R}$.
\end{theorem}
\begin{synopsis}
\end{synopsis}
\begin{proof}
\end{proof}

\section{The Convolution Theorem for Fourier Tranforms}
\begin{theorem}
	Let \( f,g \in L(\mathbb{R}) \) and either $f$ or $g$ is continuous and bounded on $\mathbb{R}$. Let \( h = f \ast g \). Then for every real $u$,
	\[ \int_{-\infty}^\infty h(x) e^{-ixu} dx = \left( \int_{-\infty}^\infty f(t) e^{-itu} dt \right) \left( \int_{-\infty}^\infty g(y) e^{-iyu} dy \right) \]
	The integral on the left exists both as a Lebesgue integral and an improper Riemann integral.
\end{theorem}
\begin{synopsis}
\end{synopsis}
\begin{proof}
\end{proof}

\begin{remark}[Application of Convolution Theorem]
	\[ B(p,q) = \frac{\Gamma{p} \Gamma{q}}{\Gamma{p+q}},\text{ where } B(p,q) = \int_0^1 x^{p-1} (1-x)^{q-1} dx,\ \Gamma{p} = \int_0^\infty t^{p-1} e^{-t} dt \]
\end{remark}

\chapter{Multivariate Differential Calculus}

	In this chapter, we deal with real functions of several variables. Instead of $\mathbf{c}$, we write \( \overline{c} \in \mathbb{R}^n \), then \( \overline{c} = (c_1, c_2, \dotsc, c_n) \) where \( c_j \in \mathbb{R} \) for every \(j = 1,2, \dotsc, n\). Again, suppose \(f : \mathbb{R}^n \to \mathbb{R}^m\) and \(f(\overline{x}) = \overline{y}\), then \(\overline{y} = (y_1, y_2, \dotsc, y_m)\) where each $y_k$ is real. The unit co-ordinate vector, $\overline{u_k}$ is given by \( {u_k}_j = \delta_{j,k} \)

\section{Directional Derivative}
	\textsl{Motivation : The existence of all partial derivatives of a multivariate real function $f$ at a point $\overline{c}$ doesn't imply the continuity of $f$ at $\overline{c}$. Thus, we need a suitable generalisation for the partial derivative which could characterise continuity. And directional derivative is such an attempt.}

\begin{definition}[Directional Derivative]
	Let \(S \subset \mathbb{R}^n\) and \(f : S \to \mathbb{R}^m\). Let $\overline{c}$ be an interior points of $S$ and \( \overline{u} \in \mathbb{R}^n \), then there exists an open ball $B(\overline{c},r)$ in $S$. Also for some $\delta > 0$ the line segment \( \alpha : [0,\delta] \to S \) given by \( \alpha(t) = \overline{c}+t\overline{u} \) lie in $B(\overline{c},r)$.\\
	
	Then the Directional derivative of $f$ at an interior point $\overline{c}$ in the direction $\overline{u}$ is given by
	\[ f'(\overline{c},\overline{u}) = \lim_{h \to 0} \frac{f(\overline{c}+h\overline{u}) - f(\overline{c})}{h} \]
\end{definition}

\begin{remark}
	The direction derivative of $f$ at an interior point $\overline{c}$ in the direction $\overline{u}$ exists only if the above limit exists.
\end{remark}

\begin{remark}Example, \cite[Exercise 12.2a]{apostol}\\
	Suppose \(\overline{x},\overline{a},\overline{c},\overline{u} \in \mathbb{R}^n\). Let \(f : \mathbb{R}^n \to \mathbb{R}\) such that \(f(\overline{x}) = \overline{a}\cdot\overline{x}\). Then
	\[ f'(\overline{c},\overline{u}) = \lim_{h \to 0} \frac{\overline{a}\cdot(\overline{c}+h\overline{u}) - \overline{a}\cdot\overline{c}}{h} = \overline{a}\cdot\overline{u}\]
\end{remark}

\begin{remark}[Properties] Let \(f : S \to \mathbb{R}^m \), where \( S \subset \mathbb{R}^n\)
	\begin{enumerate}
		\item \( f'(\overline{c},\overline{0}) = \overline{0} \)\\
			\textsl{Note : The zero vectors belongs to $\mathbb{R}^n, \mathbb{R}^m$ respectively.}
		\item \( f'(\overline{c},\overline{u_k}) = \frac{\partial f}{\partial u_k}(\overline{c}) = D_k f(\overline{c}) \), the $k^{th}$ partial derivative of $f$.
		\item Let \( f = (f_1, f_2, \cdots, f_m), \text{ such that } f(\overline{c}) = \left(f_1(\overline{c}),f_2(\overline{c}),\dotsc,f_m(\overline{c})\right) \). Then, 
			\[ \exists f'(\overline{c},\overline{u}) \iff \forall k, \exists f_k'(\overline{c},\overline{u}) \text{ and } f'(\overline{c},\overline{u}) = \left(f_1'(\overline{c},\overline{u}),f_2'(\overline{c},\overline{u}),\dotsc,f_m'(\overline{c},\overline{u})\right) \]
			ie, Directional derivative of $f$ exists iff directional derivative of each component function $f_k$ exists. And the components of the directional derivatives of $f$ are the directional derivaties of the components of $f$.\\
			Thus \( D_k f(\overline{c}) = \left(D_k f_1(\overline{c}),D_k f_2(\overline{c}),\dotsc,D_k f_m(\overline{c}) \right) \) holds.
		\item Let \( F(t) = f(\overline{c}+t\overline{u}) \), then \( F'(0) = f'(\overline{c},\overline{u}) \) and \( F'(t) = f'(\overline{c}+t\overline{u},\overline{u}) \)
		\item Let \( f(\overline{c}) = \overline{c}\cdot\overline{c} = \|\overline{c}\|^2 \), and \(F(t) = f(\overline{c}+t\overline{u}) \), then \( F'(t) = 2\overline{c}\cdot\overline{u}+2t\|\overline{u}\|^2 \) and \( F'(0) = f'(\overline{c},\overline{u}) = 2\overline{c}\cdot\overline{u} \)
		\item Let \(f\) be linear, then \( f'(\overline{c},\overline{u}) = f(\overline{u}) \)
		\item Existence of all partial derivatives doesn't imply existence of all directional derivatives.
			\[ f(x,y) = \begin{cases} x+y \qquad \text{ if } x = 0 \text{ or } y = 0 \\ 1 \qquad \qquad \text{otherwise} \end{cases} \]
			For above \(f\), directional derivatives exists only along the co\nobreakdash-ordinates (ie, partial derivatives).
		\item Existence of all directional derivatives doesn't imply continuity.
			\[ f(x,y) = \begin{cases} xy^2(x^2+y^4) \qquad x \ne 0 \\ 0 \hspace{2.5cm} x = 0 \end{cases} \]
				Above \(f\) is discontinuous at \((0,0)\), however all directional derivatives exists and has finite value.
	\end{enumerate}
\end{remark}

\section{Total Derivative}
	We may define a total derivative \( T_c(h) = hf'(c) \) in the case of real-functions of single variable as follows :-\\

	\[ \text{Let }E_c(h) = \begin{cases} \frac{f(c+h)-f(c)}{h} - f'(c),\qquad h \ne 0 \\ 0,\hspace{3.4cm} h = 0 \end{cases} \]
		Then, \( f(c+h) = f(c) + hf'(c) + hE_c(h) \) and as \( h \to 0 \), \( E_c(h) \to 0\). Also \( T_c(h) = f'(c)h \) is a linear function of $h$. ie, \( T_c(ah_1+bh_2) = aT_c(h_1)+bT_c(h_2) \). Now, we will define a total derivative of multivariate function that has these two properties.

\begin{definition}[Total Derivative]
	The function \( f: \mathbb{R}^n \to \mathbb{R}^m \) is differentiable at $\overline{c}$ if there exists a \textbf{linear} function \( T_{\overline{c}} : \mathbb{R}^n \to \mathbb{R}^m \) such that \( f(\overline{c}+\overline{v}) = f(\overline{c}) + T_{\overline{c}}(\overline{v}) + \|\overline{v}\| E_{\overline{c}}(\overline{v}) \) where \( E_{\overline{c}}(\overline{v}) \to 0 \) as \( \overline{v} \to 0 \).
\end{definition}

	The linear function $T_{\overline{c}}$ is the total derivative of $f$ as $\overline{c}$ and the condition above is the First Order Taylor's Formula for $f(\overline{c}+\overline{v})$.

\begin{theorem}
	If $f$ is differentiable at $\overline{c}$ with total derivative $T_{\overline{c}}$, then for every $\overline{u} \in \mathbb{R}^n$, $T_{\overline{c}}(\overline{u}) = f'(\overline{c},\overline{u})$.
\end{theorem}
\begin{proof}
	For \( \overline{v} = \overline{0}$, we have $T_{\overline{c}}(\overline{0}) = 0 = f'(\overline{c},\overline{0}) \).\\

	Suppose \( \overline{v} \ne \overline{0} \), then \( \overline{v} = h\overline{u} \) for some \( \overline{u} \). Since $f$ is differentiable at $\overline{c}$, $f$ has total derivative at $\overline{c}$. That is, there exists a linear function $T_{\overline{c}}$ such that \( f(\overline{c}+h\overline{u}) = f(\overline{c}) + T_{\overline{c}}(h\overline{u}) + \|h\overline{u}\|E_{\overline{c}} (h\overline{u}) \) where $E_{\overline{c}}(h\overline{u}) \to \overline{0}$ as $h\overline{u} \to \overline{0}$.

	\begin{align*}
		\implies  & f(\overline{c}+h\overline{u}) = f(\overline{c}) + hT_{\overline{c}}(\overline{u}) + |h|\|\overline{u}\|E_{\overline{c}} (h\overline{u}),\ E_{\overline{c}}(h\overline{u}) \to \overline{0} \text{ as } h\overline{u} \to \overline{0} \\
		\implies  & \frac{f(\overline{c}+h\overline{u}) - f(\overline{c})}{h} = T_{\overline{c}}(\overline{u}) + \frac{|h|\|\overline{u}\|E_{\overline{c}}(h\overline{u})}{h},\  E_{\overline{c}}(h\overline{u}) \to \overline{0} \text{ as } h \to 0 \\
		\implies  & \lim_{h \to 0} \frac{f(\overline{c}+h\overline{u}) - f(\overline{c})}{h} = T_{\overline{c}}(\overline{u}) + \lim_{h \to 0} \frac{|h|\|\overline{u}\|E_{\overline{c}}(h\overline{u})}{h} \\
		\implies & f'(\overline{c},\overline{u}) = T_{\overline{c}}(\overline{u})
	\end{align*}
\end{proof}

\begin{remark}
	$T_{\overline{c}}$ is linear, however $E_{\overline{c}}$ is not linear. Thus $E_{\overline{c}}(h\overline{u}) \ne h E_{\overline{c}} (\overline{u})$.\\

	As $h \to 0$, $h\overline{u} \to \overline{0}$ and \( E_{\overline{c}}(h\overline{u}) \to \overline{0}$. Since the order of the function \( E_{\overline{c}}(h\overline{u}) \) is much smaller than that of $h$, the limit on the right converges to 0.
\end{remark}

\chapter{Implicit Functions and Extremum Problems}
%\chapter{Multiple Riemann Integrals*}
%\chapter{Multiple Lebesgue Integrals*}
%\chapter{Cauchy's Theorem and the Residue Calculus*}
%\cite{rudin}

