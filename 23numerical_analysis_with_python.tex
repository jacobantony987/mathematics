%Text books : \cite{brigs}, \cite{saha}, \cite{kiusalaas}
%Module 1:
%Defining Symbols and Symbolic Operations, Working with Expressions, Solving Equations and Plotting Using SymPy, problems on factor finder, summing a series and solving single variable inequalities
%Chapter 4 of \cite{saha} 
%Module 2:
%Finding the limit of functions, finding the derivative of functions, higher-order derivatives and finding the maxima and minima and finding the integrals of functions are to be done. in the section programming challenges, the following problems - verify the continuity of a function at a point, area between two curves and finding the length of a curve
%Chapter 7 of \cite{saha} 
%Module 3:
%Interpolation and Curve Fitting - Polynomial Interpolation - Lagrange's Method, Newton's Method and Limitations of Polynomial Interpolation, Roots of Equations - Method of Bisection and Newton-Raphson Method.
%Sections 3.1, 3.2, 4.1, 4.3, 4.5 of \cite{kiusalaas}
%Module 4:
%Gauss Elimination Method (excluding Multiple Sets of Equations), Doolittle's Decomposition Method only from LU Decomposition Methods, Numerical Integration, Newton-Cotes Formulas, Trapezoidal rule, Simpson's rule and Simpson's 3/8 rule.
%Sections 2.2, 2.3, 6.1, 6.2 of \cite{kiusalaas}

%Programs
%Online Program, Explanation, Algorithm, Function Syntax, Terminology
\part{ME010203 Numerical Analysis with Python}
\chapter{Expressions}
\chapter{Calculus}
\chapter{Interpolation \& Curve Fitting}
\begin{definition}
	Given $(n+1)$ data points $(x_k, y_k),\ k = 0,1,\cdots,n$, the problem of estimating $y(x)$ using a function $y : \mathbb{R} \to \mathbb{R}$ that satisfy the data points is the interpolation problem. ie, $y(x_k) = y_k,\ k = 0,1,\cdots,n$.
\end{definition}
\begin{definition}
	Given $(n+1)$ data points $(x_k,y_k),\ k = 0,1,\cdots,n$, the problem of estimating $y(x)$ using a function $y : \mathbb{R} \to \mathbb{R}$ that is sufficiently close to the data points is the curve-fitting problem.\\ ie, Given $\epsilon > 0,\ |y(x_k)-y_k| < \epsilon,\ k = 0,1,\cdots,n$.
\end{definition}
\begin{remark}
	The data could be from scientific experiments or computations on mathematical models. The interpolation problem assumes that the data is accurate. But, curve-fitting problem assumes that there are some errors involved which are sufficiently small.
\end{remark}
\begin{definition}
	Given $(n+1)$ data points $(x_k,y_k),\ k = 0,1,\cdots,n$, the problem of estimating $y(x)$ using a polynomial function of degree $n$ that satisfy the data points is the polynomial interpolation problem.
\end{definition}
\begin{remark}
	Polynomial is the simplest interpolant.\cite[3.2]{kiusalaas}
\end{remark}

\section{Polynomial Interpolation}
There exists a unique polynomial of degree $n$ that satisfy $(n+1)$ distinct data points. There are a few methods to find this polynomial : 
\begin{enumerate*}
	\item Lagrange's method
	\item Newton's method
	\item Neville's method
\end{enumerate*}. The Neville's method is out of scope.

\subsection{Lagrange's Method}
Interpolation polynomial\footnote{Using $P_n$ to represent some polynomial of degree $n$. It is quite a confusing a notation when it comes to Newton's method as author construct a psuedo-recursive definition.} is given by,
\begin{equation}
	P(x) = \sum_{i=0}^n y_i l_i(x),\text{ where } \l_i(x) = \prod_{j = 0,j \ne i}^n \frac{x-x_i}{x_j-x_i}
	\label{equ:lagrange}
\end{equation}
\begin{remark}
	Lagrange's cardinal functions $l_i$, are polynomials of degree $n$ and
	$$l_i(x_j) = \delta_{ij} = \begin{cases} 0,\ i = j \\ 1,\ i \ne j \end{cases}$$
\end{remark}
\begin{proposition}
	Error in polynomial interpolation is given by
	\begin{equation}
		f(x) - P(x) = \frac{(x-x_0)(x-x_1)\cdots(x-x_n)}{(n+1)!} f^{(n+1)}(\xi)
		\label{equ:error}
	\end{equation}
	where $\xi \in (x_0, x_n)$
\end{proposition}
\begin{remark}
	The error increases as $x$ moves away from the unknown value $\xi$.
\end{remark}

\subsection{Newton's Method}
The interpolation polynomial is given by,
\begin{equation}
	P(x) = a_0 + a_1(x-x_0) + \cdots + a_n(x-x_0)(x-x_1)\cdots(x-x_{n-1})
	\label{equ:newton}
\end{equation}
where $a_i = \nabla^i y_i,\ i = 0,1,\cdots,n$.
\begin{remark}
	For Newton's Method, it is assumed that $x_0 < x_1 < \cdots < x_n$.
\end{remark}
\begin{remark}
	 Lagrange's method is conceptually simple. But, Newton's method is computationaly more efficient than Lagrange's method.
\end{remark}
\subsubsection{Computing coefficients $a_i$ of the polynomial}
The coefficients are given by,
\begin{equation}
	a_0 = y_0,\ a_1 = \nabla y_1,\ a_2 = \nabla^2 y_2,\ a_3 = \nabla^3 y_3,\cdots, a_n = \nabla^n y_n
\end{equation}
\begin{remark}
	The divided difference $\nabla^i y_i$ are computed as follows:
	\begin{align*}
		\nabla y_1 = \frac{y_1 - y_0}{x_1 - x_0} & & \\
		\nabla y_2 = \frac{y_2 - y_1}{x_2 - x_1} &\qquad \nabla^2 y_2 = \frac{\nabla y_2 - \nabla y_1}{x_2-x_1} & \\
		\nabla y_3 = \frac{y_3 - y_2}{x_3 - x_2} &\qquad \nabla^2 y_3 = \frac{\nabla y_3 - \nabla y_2}{x_3-x_2} & \nabla^3 y_3 = \frac{\nabla^2 y_3 - \nabla^2 y_2}{x_3-x_2}
	\end{align*}
\end{remark}
\begin{table}[hb]
	\centering
	\begin{tabular}{|c||c|c|c|c|c|}
		\hline
		$x_0$ & $y_0$ & & & & \\ \hline
		$x_1$ & $y_1$ & $\nabla y_1$ & & &   \\ \hline
		$x_2$ & $y_2$ & $\nabla y_2$ & $\nabla^2 y_2$ & &   \\ \hline
		\dots & \dots & \dots & \dots & $\ddots$ & \\ \hline
		$x_n$ & $y_n$ & $\nabla y_n$ & $\nabla^2 y_n$ & \dots & $\nabla^n y_n$  \\ \hline
	\end{tabular}
	\caption{The $\nabla^i y_i$ Computation Table}
\end{table}

\begin{remark}
	Practise Problems\\
	Find interpolation polynomial for the following data points :
	\begin{enumerate}
		\item $\{(0,7),\ (2,11),\ (3,28)\}$\\ \cite[Example 3.1]{kiusalaas}
		\item $\{(-2,-1),\ (1,2),\ (4,59),\ (-1,4),\ (3,24),\ (-4,-53) \}$\\ \cite[Example 3.2]{kiusalaas}
		\item $\{(-1.2,-5.76),\ (0.3,-5.61),\ (1.1,-3.69)\}$\\ \cite[Problem Set 3.1.1]{kiusalaas}
	%	\item $\{(0,-1.00),\ (0.5,1.75),\ (1,4.00),\ (1.5,5.75),\ (2,7.00)\}$\\ \cite[Problem Set 3.1.4]{kiusalaas}
		\item $\{(-2,-1),\ (1,2),\ (4,59),\ (-1,4),\ (3,24),\ (-4,-53)\}$\\ \cite[Problem Set 3.1.6]{kiusalaas}
		\item $\{(-3,0),\ (2,5),\ (-1,-4),\ (3,12),\ (1,0)\}$\\ \cite[Problem Set 3.1.7]{kiusalaas}
		\item $\{(0,1.225),(3,0.905),(6,0.652)\}$\\ \cite[Problem Set 3.1.9]{kiusalaas}
	\end{enumerate}
\end{remark}

\begin{remark}
	In Lagrange's Method, we can interpolate at the given point even without computing the polynomial. In Newton's method, we have to compute polynomial and then interpolate for the given point.\\

	That is, evaluate the value of cardinal polynomials at the point and substitute in Equation \ref{equ:lagrange} as shown in Section 3.2.\cite[Example 3.1]{kiusalaas}
\end{remark}

\subsection{Implementation of Newton's Method}

\begin{program}Computing Coefficients
	\begin{python}
		def coefficients(xData,yData):
			m = len(xData)
			a = yData.copy()
			for k in range(1,m):
				a[k:m] = (a[k:m]-a[k-1])/(xData[k:m]-xData[k-1])
			return a
	\end{python}
	Line 1 : \textbf{Defines a function which takes two arguments/parameters, named $xData$ and $yData$.} In \cite[3.2]{kiusalaas}, you will find coeffts which I have changed to coefficients. $xData$,$yData$ are numpy array objects. $xData$ is a array with values $x_0,x_1,\cdots,x_n$. And $yData$ is array with values $y_0,y_1,\cdots,y_n$. For example, the value of $x_3$ can be accessed as $xData[3]$.\\
	
	Line 2 : \textbf{The functon $len()$ is extended by numpy to give the length of array objects.} In this context, $len(xData)$ will return the value $n+1$, since there are $n+1$ values in $xData$ array.\\

	Line 3 : We need a copy of $yData$ to work with. Unlike other programming languages like java, in python $a = yData$ will assign a new label $a$ to the same memory location and manipulating $a$ will corrupt the original data in $yData$ as well. In order to avoid this, we are \textbf{making a copy of the array object using the array method provided by the numpy library.}\\

	Line 4 : \textbf{This is a python loop statement. This ask python interpreter to repeat the following sub-block $m-1$ times.}\footnote{Python block is a group of statement with same level of indentation. A sub-block is a block with an additional indentation.} In this context, Line 5 will be executed $n$ times, since the $range(1,m)$ object is a list-type object with values $1,2,\cdots,m-1$. And intepreter executes Line 5 for each values in the $range()$ object, ie, $k=1,2,\cdots, m-1$ before interpreting Line 6.\\

	Line 5 : This is very nice feature available in python. \textbf{This statement, evaluates $m-k$ values in a single step.ie, $a[k],a[k+1],\cdots,a[m]$. This calculation corresponds to subsequent columns of the divided difference table, that we are familiar with.} For example, executing Line 5 with $k=3$ is same as evaluating the $\nabla^3y_j$ column. Note that the value $a[0]$ is never updated and similarly $a[2]$ changes when Line 5 is executed with $k=1,2$. From column 3 onward, $a[2]$ is not updated. Therefore, \textbf{after completing $n$th executing of the Line 5, we have $a[0] = y_0,\ a[1]=\nabla y_1,\ a[2]=\nabla^2 y_2,\cdots,\ a[n]=\nabla^n y_n$.}\\

	Line 6 : \textbf{This returns the array $a$ which is the array of coefficients.}\\

	The logic of this program is in Line 4 and Line 5. So they need more explanation/understanding than anything else.
\end{program}

\begin{program}Interpolating using Newton's Method
	\begin{python}
		def interpolate(a,xData,x):
			n = len(xData)-1
			p = a[n]
			for k in range(1,n+1):
				p = a[n-k]+(x-xData[n-k])*p
			return p
	\end{python}
	The logic this program is in Line 3, Line 4 and Line 5.\\

	Line 3 : We initialize the polynomial with the coefficient $a[n] = \nabla^n y_n = a_n$.\\

	Line 4 : We are going define the polynomial recursively. This takes exactly $n$ steps further. So we use a loop which repeats $n$ times.\\

	Line 5 : The value of $p$ and $k$ changes each time Line 5 is executed. Let $P_j$ be the value in $p$ after executing Line 5 with $k=j$. Then,\\ $P_0 = p = a[n]$\\ $P_1 = a[n-1]+(x-x_{n-1})P_0$\\ $P_2 = a[n-2]+(x-x_{n-2})P_1$\\ $\vdots$\\ $P_n = a[0]+(x-x_0)P_{n-1}$.\\ Clearly, $P_n$ is the unique $n$ degree polynomial given by the Newton's method.
\end{program}

\begin{program}How to interpolate ?
	\begin{python}
		from numpy import array
		xData = array([-2,1,4,-1,3,-4]) #change as needed
		yData = array([-1,2,59,4,24,-53]) #change as needed
		a = coefficients(xData,yData)
		print(interpolate(a,xData,2))
	\end{python}

	You will have to define both the functions (coefficients, interpolate) before doing this.\\

	Line 1 : For defining array objects, we need to import them from numpy library.\\

	Line 2 : You can change this line according to the first component of the given data points.\\

	Line 3 : You can change this line according to the second component of the given data points.\\

	Line 4 : Call function \texttt{coefficients} and store the array returned into a\\

	Line 5 : Call function \texttt{interpolate} to interpolate at $x = 2$ and print the value $P(2)$
\end{program}

\begin{program}[Just for Fun]
	We can do more using sympy !
	\begin{python}
		from numpy import array
		from sympy import Symbol
		xData = array([-2,1,4,-1,3,-4])
		yData = array([-1,2,59,4,24,-53])
		a = coefficients(xData,yData)
		x = Symbol('x')
		p = interpolate(a,xData,x)
		p.subs({x:2})
	\end{python}
\end{program}

\begin{remark}
	Programming Problems
	\begin{enumerate}
%		\item $\{(4.0,-0.06604),\ (3.9,-0.02724),\ (3.8,0.01282),\ (3.7,0.05383)\}$\\ \cite[Example 3.3]{kiusalaas}
		\item $\{(0.15,4.79867),\ (2.30,4.49013),\ (3.15,4.2243),\ (4,85,3.47313),\\ (6.25,2.66674),\ (7.95,1.51909)\}$ \cite[Example 3.4]{kiusalaas}
%		\item $\{(0,1.8421),\ (0.5,2.4694),\ (1,2.4921),\ (1.5,1.9047),\ (2,0.8509),\ (2.5,-0.4112),\ (3,-1.5727)\}$\\ \cite[Problem Set 3.1.2]{kiusalaas}
		\item $\{(0,-0.7854),\ (0.5,0.6529),\ (1,1.7390),\ (1.5,2.2071),\ (2,1.9425)\}$\\ \cite[Problem Set 3.1.5]{kiusalaas}
	\end{enumerate}
\end{remark}
\subsection{Limitations of Polynomial Interpolation}
\begin{enumerate}
	\item Inaccuracy - The error in interpolation increases as the point moves away from most of the data points.
	\item Oscilation - As the number of data points considered for polynomial interpolation increases, the degree of the polynomial increases. And the graph of the interpolant tend to oscilate excessively. In such cases, the error in interpolation is quite high. 
	\item The best practice is to consider four to six data points nearest to the point of interest and ignore the rest of them.
\end{enumerate}
\begin{remark}
	The interpolant obtained by joining cubic polynomials corresponding to four nearest data points each, is a cubic spline\footnote{Cubic spline is a function, the graph of which is piece-wise cubic}.
\end{remark}

\chapter{Matrix Operations}

