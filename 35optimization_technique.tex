%Text Books : \cite{mital}, \cite{solberg}
%Module 1 : Linear Programming
%Simplex Method, Canonical form of equations, Simplex Method (Numerical Example), Simplex Tableau, Finding the first BFS and artificial variables, Degeneracy, Simplex multipliers, Revised simplex method, Duality in LPP, Duality theorems, Applications of Duality, Dual simplex method, Summery of simplex methods.
%(Chapter 3; sections: 9 - 21 of \cite{mital}) (25 hours)
%Module 2 : Integer Programming
% I. L. P. in two dimensional space, General I.L.P. and M.I.L.P. problems, cutting planes, remarks on cutting plane methods, branch and bound method, examples, general description, the 0-1 variable.
%(Chapter 6; sections: 6.1 - 6.10 of \cite{mital}) (25 hours)
%Module 3 : Goal Programming, Flow and potentials in Networks
%Goal programming. Graphs- definitions and notation, minimum path problem, spanning tree of minimum length, problem of minimum potential difference, scheduling of sequential activities, maximum flow problem, duality in the maximum flow problem, generalized problem of maximum flow.
%(Chapter - 5 & 7 Sections 5.9 & 7.1 to 7.9, 7.15 of \cite{mital}) (15 hours)
%Module 4 : Non-linear Programming
%Basic concepts - Taylorâ€™s series expansion, Fibonacci Search, golden section search, Hooke and Jeeves search algorithm, gradient projection search, Lagrange multipliers, equality constraint optimization, constrained derivatives, non-linear optimization: Kuhn-Tucker conditions, complimentary Pivot algorithms.
%(Chapter 11; Sections: 11.1 - 11.7, 11.9- 11.11 of \cite{solberg}) (25 hours)

%Module 1 - \cite{mital} 3
%Module 2 - \cite{mital} 6
%Module 3 - \cite{mital} 5, 7
%Module 4 - \cite{solberg} 11

%Module 1
\section{Linear Programming}
\begin{definition}[LPP]
Linear Programming Problem (LPP) is the optimization of linear object function under certain linear equality/inequalities constraints.
\end{definition}
\paragraph{General LPP}
A general LPP is of the form,
\begin{align}
	\text{ minimise } & : & f(X) = CX  & \text{ (object function)} \label{eqn:obj} \\
	\text{ subject to } & : & AX = B & \text{ (linear constraints)}\label{eqn:sub} \\
	\text{ such that } & & X \ge 0 & \text{ (non-negativity conditions)}\label{eqn:positive}
\end{align}

	That is,
\begin{align}
\text{ minimise } & : & f = c_1x_1 + c_2x_2 + \dotsb + c_nx_n & \\
\text{ subject to } & : & \begin{pmatrix} a_{11} & a_{12} & \dots & a_{1m} \\ a_{21} & a_{22} & \dots & a_{2m} \\ \vdots & \vdots & \ddots & \vdots \\ a_{m1} & a_{m2} & \dots & a_{mm} \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \\ \dots \\ x_m \end{pmatrix} & = \begin{pmatrix} b_1 \\ b_2 \\ \vdots \\ b_m \end{pmatrix} \\
\text{ such that } & & X \ge 0 &
\end{align}

	The coefficients of the object function, $c_i$ are the \textbf{cost coefficients}.

\paragraph{Feasible Solution} is a vector $X$ satisfying both constraints and non-negativity constraints. The set of all feasible solutions is denoted by $S_F$. This is a convex set and is often represented graphically by a polytope.

\paragraph{Basic Solution} In an LPP with $m$ constraints and $n$ variables, a \textbf{basic solution} is a vector $X$ in which $n-m$ variables are zero. These variables are the non-basic variables and the remaining $m$ variables are the basic variable. The set of all basic variables is a \textbf{basis}.

\paragraph{Basic Feasible Solution} is a basic solution which is feasible. The \textbf{b.f.s.} are vertices of the polytope $S_F$ (if nonempty).

\paragraph{Optimal Solution} is a vector $X$ which optimizes the object function $f$. For a bounded $S_F$, always there exists a b.f.s which is optimal.

\paragraph{Solving LPP} Due to the presence of inequalities, there is no analytic tool for solving an LPP. There are a few numerical methods for solving an LPP. Simplex is popular among them.

\paragraph{Simplex Algorithm}
	First, we compute a b.f.s. (which is a vertex of the polytope $S_F$). If there is a desirable b.f.s. (an  adjancent vertex) which improves the object function, then we jump to the corresponding b.f.s. (vertex). We continue this process until there is no scope of further improvement.

\paragraph{Canonical Form}
	Consider the LPP (in matrix form)
\begin{align*}
\text{ minimise } & f(X) = CX \\
\text{ subject to } & AX = B \\
\text{ such that } & X \ge 0  
\end{align*}
\begin{commentary}
\begin{align*}
	\intertext{Rearranging the non-basic variable, we get}
	\begin{pmatrix} a_{11} & a_{12} & \dots & a_{1m} \\ a_{21} & a_{22} & \dots & a_{2m} \\ \vdots & \vdots & \ddots & \vdots \\ a_{m1} & a_{m2} & \dots & a_{mm} \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_m \end{pmatrix} & = \begin{pmatrix} b_1 - a_{1,(m+1)} x_{m+1} - a_{1,(m+2)} x_{m+2} - \dotsb - a_{1n}x_n \\ b_2 - a_{2,(m+1)} x_{m+1} - a_{2,(m+2)} x_{m+2} - \dotsb - a_{2,n}x_n \\ \vdots \\ b_m-a_{m,(m+1)}x_{m+1} - a_{m,(m+2)}x_{m+2}-\dotsb-a_{m,n}x_n \end{pmatrix}
\end{align*}
Left multplying with $A^{-1}$ on either sides, we get
\begin{align*}
	\begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_m \end{pmatrix} = & \begin{pmatrix} \bar{b}_1 - \bar{a}_{1,(m+1)} x_{m+1} - \bar{a}_{1,(m+2)} x_{m+2} - \dotsb - \bar{a}_{1n}x_n \\ \bar{b}_2 - \bar{a}_{2,(m+1)} x_{m+1} - \bar{a}_{2,(m+2)} x_{m+2} - \dotsb - \bar{a}_{2,n}x_n \\ \vdots \\ \bar{b}_m-\bar{a}_{m,(m+1)}x_{m+1} - \bar{a}_{m,(m+2)}x_{m+2}-\dotsb-\bar{a}_{m,n}x_n \end{pmatrix}\\
		\text{where } & \begin{pmatrix} \\ A^{-1} \\ \hphantom{} \end{pmatrix} \begin{pmatrix} b_1 \\ b_2 \\ \dots \\ b_m \end{pmatrix} = \begin{pmatrix} \bar{b}_1 \\ \bar{b}_2 \\ \vdots \\ \bar{b}_m \end{pmatrix} \text{ and } \begin{pmatrix} \\ A^{-1} \\ \hphantom{} \end{pmatrix} \begin{pmatrix} a_{1,(m+1)} \\ a_{2,(m+1)} \\ \vdots \\ a_{m,(m+1)} \end{pmatrix} = \begin{pmatrix} \bar{a}_{1,(m+1)} \\ \bar{a}_{2,(m+1)} \\ \vdots \\ \bar{a}_{m,(m+1)} \end{pmatrix}
\end{align*}

The constraints \[ \sum_{j=1}^n a_{ij}x_j = b_i, \qquad j = 1,2,\dots,n \] in the form, \[ x_i + \sum_{j=m+1}^n \bar{a}_{i,j} = \bar{b}_i, \qquad i=1,2,\dots,m\] is said to be canonical.
Also we can replace $x_i$'s in object function to get, 
\[ f(X) = \sum_{i=1}^m c_i \left( \bar{b}_i - \sum_{j=m+1}^n \bar{a}_{ij}x_j \right) + \sum_{j=m+1}^n c_jx_j = \sum_{i=1}^m c_i\bar{b}_i + \sum_{i=m+1}^n \bar{c}_jx_j \]
where $\displaystyle \bar{c}_j = c_j - \sum_{i=1}^m c_i \bar{a}_{ij},\ j = m+1,m_2,\dots,n$.
 From the canonical form, we can compute the corresponding b.f.s., $X = (\bar{b}_1,\bar{b}_2,\dots,\bar{b}_m,0,0,\dots,0)$ and object function $\displaystyle f(X) = \sum_{i=1}^m \bar{b}_ic_i $ since $\bar{c}_j$ are zero for $j > m$. These $\bar{c}_j$'s are called the \textbf{relative cost coefficients}.
\end{commentary}

\subsection{Simplex Method}
\begin{align*}
\text{ minimise : } & f(x) = 6x_1 - 2x_2 +4x_3 - 5x_4\\
\text{ subject to : } & 4x_1 - x_2 + 2x_3 - 3x_4 \le 1 \\
& x_2 + 4x_3 - 2x_4 \le 2 \\
& x_1,x_2,x_3,x_4 \ge 0
\end{align*}
\begin{figure}[hbt]
\centering
\begin{tabular}{c|c|c|c|c|c|c|c|c|}\hline
Phase & Basis & B & $P_1$ & $P_2$ & $P_3$ & $P_4$ & $P_5$ & $P_6$ \\ \hline
1 & $x_5$ & 1 & 4 & -1 & 2 & \textcolor{red}{$3$} & 1 & 0  \\ 
  & $x_6$ & 2 & 0 &  1 & 0 & $4$ & 0 & 1 \\ \hline
  & $f$   & 0 & 6 & -2 & 4 & -5 & 0 & 0 \\ \hline
	2 & $x_4$ & $\sfrac{1}{3}$ & $\sfrac{4}{3}$ & $\sfrac{-1}{3}$ & $\sfrac{2}{3}$ & 1 & $\sfrac{1}{3}$ & 0  \\ 
	& $x_6$ & $\sfrac{2}{3}$ & $\sfrac{-16}{3}$ & \textcolor{red}{$\sfrac{7}{3}$} & $\sfrac{-8}{3}$ & 0 & $\sfrac{-4}{3}$ & 1 \\ \hline
	& $f$ & $\sfrac{5}{3}$ & $\sfrac{38}{3}$ & $\sfrac{-11}{3}$ & $\sfrac{22}{3}$ & 0 & $\sfrac{5}{3}$ & 0 \\ \hline
	3 & $x_4$ & $\sfrac{3}{7}$ & $\sfrac{4}{7}$ & 0 & $\frac{2}{7}$ & 1 & \textcolor{red}{$\sfrac{1}{7}$} & $\sfrac{1}{7}$  \\ 
	& $x_2$ & $\sfrac{2}{7}$ & $\sfrac{-16}{7}$ & 1 & $\sfrac{-8}{7}$ & 0 & $\sfrac{-4}{7}$ & $\sfrac{3}{7}$ \\ \hline
	& $f$ & $\sfrac{19}{7}$ & $\sfrac{30}{7}$ & 0 & $\sfrac{22}{7}$ & 0 & $\sfrac{-3}{7}$ & $\sfrac{11}{7}$ \\ \hline
	4 & $x_5$ & 3 & 4 & 0 & 2 & 7 & 1 & 1 \\
	  & $x_2$ & 2 & 0 & 1 & 0 & 4 & 0 & 1 \\ \hline
	  & $f$   & 4 & 6 & 0 & 4 & 3 & 0 & 2 \\ \hline
\end{tabular}
\caption{Simplex Steps}
\end{figure}

\subsection{Unrestricted Variable}
\begin{align*}
\text{ minimise : } & f(x) = 6x_1 - 2x_2 +4x_3 - 5x_4\\
\text{ subject to : } & 4x_1 - x_2 + 2x_3 - 3x_4 \le 1 \\
& x_2 + 4x_3 - 2x_4 \le 2 \\
& x_1,x_2,x_4 \ge 0 \text{ and } x_3 \text{ unrestricted}
\end{align*}
	In above LPP, the variable $x_3$ is unrestricted. Replace $x_3$ with two variables $x_{31}$ and $x_{32}$ such that $x_3 = x_{31}-x_{32},\ x_{31} \ge 0,\ x_{32} \ge 0$. We get,
\begin{align*}
	\text{ minimise : } & f(x) = 6x_1 - 2x_2 +4x_{31}-4x_{32} - 5x_4\\
	\text{ subject to : } & 4x_1 - x_2 + 2x_{31}-2x_{32} - 3x_4 \le 1 \\
	& x_2 + 4x_{31}-4x_{32} - 2x_4 \le 2 \\
	& x_1,x_2,x_{31},x_{32},x_4 \ge 0
\end{align*}

\subsection{Artificial Variable}
\begin{align*}
\text{ minimise : } & f(x) = 6x_1 - 2x_2 +4x_3 - 5x_4\\
\text{ subject to : } & 4x_1 - x_2 + 2x_3 - 3x_4 \le 1 \\
& x_2 - 4x_3 + 2x_4 \le -2 \\
& x_1 - 2x_2 + x_3 \le -5 \\
& x_1,x_2,x_3,x_4 \ge 0
\end{align*}
First, we need to change all right-hand side constants into on-negative.
\begin{align*}
\text{ minimise : } & f(x) = 6x_1 - 2x_2 +4x_3 - 5x_4\\
\text{ subject to : } & 4x_1 - x_2 + 2x_3 - 3x_4 \le 1 \\
& -x_2 + 4x_3 - 2x_4 \ge 2 \\
& -x_1 + 2x_2 - x_3 \ge 5 \\
& x_1,x_2,x_3,x_4 \ge 0
\end{align*}
Now we need to introduce three slack variables $x_5,x_6,x_7$,
\begin{align*}
\text{ minimise : } & f(x) = 6x_1 - 2x_2 +4x_3 - 5x_4\\
\text{ subject to : } & 4x_1 - x_2 + 2x_3 - 3x_4 + x_5 = 1 \\
& -x_2 + 4x_3 - 2x_4 - x_6 = 2 \\
& -x_1 + 2x_2 - x_3 - x_7 = 5 \\
& x_1,x_2,x_3,x_4,x_5,x_6,x_7 \ge  0
\end{align*}

\subsubsection{Two Phase Method}
First phase we compute a basic feasible solution (b.f.s.) for the first iteration the simplex method from an auxiliary problem with the artificial variables $x_8,x_9$ each introduced into '$\ge$' constraints. In second phase, original problem is optimized using simplex method.\\

	If the auxiliary problem does not have a feasible solution in which every artificial variables are zero, then original LPP has no feasible solution.\\

Phase I: Auxiliary Problem
\begin{align*}
	\text{ minimise : } & g(x) = x_8 + x_9 \\
\text{ subject to : } & 4x_1 - x_2 + 2x_3 - 3x_4 + x_5 = 1 \\
& -x_2 + 4x_3 - 2x_4 - x_6 + x_8 = 2 \\
& -x_1 + 2x_2 - x_3 - x_7 + x_9 = 5 \\
& x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9 \ge  0
\end{align*}

Phase II: Origial Problem with an initial b.f.s. 
---to be corrected---
\begin{align*}
	\text{ minimise : } & f(x) = 6x_1 - 2x_2 +4x_3 - 5x_4 \\
\text{ subject to : } & 4x_1 - x_2 + 2x_3 - 3x_4 + x_5 = 1 \\
& -x_2 + 4x_3 - 2x_4 - x_6 + x_8 = 2 \\
& -x_1 + 2x_2 - x_3 - x_7 + x_9 = 5 \\
& x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9 \ge  0
\end{align*}

\subsubsection{Big M Method}
In Big M method, arbitrarily large multiples of artificial variables are added to the object function. If the optimal solution of the modified problem has any artificial variables with nonzero value, then it has no feasible solution.
\begin{align*}
	\text{ minimise : } & f(x) = 6x_1 - 2x_2 +4x_3 - 5x_4 + 100x_8 + 100x_9 \\
\text{ subject to : } & 4x_1 - x_2 + 2x_3 - 3x_4 + x_5 = 1 \\
& -x_2 + 4x_3 - 2x_4 - x_6 + x_8 = 2 \\
& -x_1 + 2x_2 - x_3 - x_7 + x_9 = 5 \\
& x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9 \ge  0
\end{align*}

%Module 2
\section{Integer Programming}
\begin{definition}
	Integer Linear Programming Problem(ILPP) is the integral conditioning of an optimization of a linear object function under certain linear equality/inequality constraints.
\end{definition}

\paragraph{General ILPP}
A general ILPP is of the form,
\begin{align}
	\text{ minimise } & : & f(X) = & CX  \text{ (object function)} \label{eqn:obj} \\
	\text{ subject to } & : & AX = & B \text{ (constraints)}\label{eqn:sub} \\
	\text{ such that } & & X \ge & 0 \text{ (non-negativity conditions)}\label{eqn:positive} \\
	and & & X \text{ is an integer vector}. & \text{ (integer condition) }
\end{align}

\begin{remark}
	Let $T_F$ be the set of all integer solutions.
	Let $[T_F]$ be the convex hull of $T_F$.
	Let $S_F$ be the set of all real solutions.
	Then, $T_F \subset [T_F] \subset S_F$.\\
	
	Finding optimal solution from $T_F$ is a much more difficult than finding optimal solution from $[T_F]$. Using Simplex method on $[T_F]$, we can find the optimal integer solutions.
\end{remark}
\pagebreak

%Module 3
\section{Networks}
\subsection{Introduction}
	Networks finds its applications in electrical circuits, transportation/logistics, communication systems.

\subsection{Graphs : Definition, Notation}
\begin{commentary}
	You don't have to learn the exact definition. But should know the differences. Definition of $\Omega^+, \Omega^-$ are important.
\end{commentary}

\begin{description}
	\item[Graph] $G(V,U)$ or $G$ is a set $V$ of elements $v_1,v_2,\dots,v_n$ represented by points and a set $U$ of pairs $(v_j,v_k),\ v_j,v_k \in V$ represented by arcs joining points of $V$.
	\item[Vertices] are the elements of $V$ in graph $G(V,U)$.
	\item[Arcs] are the elements of $U$ in graph $G(V,U)$.
	\item[Directed Arcs] An arc is directed if the pair $(v_j,v_k)$ is an ordered pair. Directed arcs are represented by arcs with a direction. 
	\item[Directed Graph] is the graph with directed arcs.
	\item[Subgraph] $G_1(V_1,U_1)$ of a graph $G(U,V)$ is a graph $G_1(V_1,U_1)$ such that $V_1 \subset V$ and $U_1$ contains \textcolor{red}{all arcs} of $G$ between the vertices of $G$.
	\item[Partial Graph] $G_1(V_1,U_1)$ of a graph $G(U,V)$ is a graph $G_1(V_1,U_1)$ such that $V_1 \subset V$ and $U_1 \subset U$.
	\item[$\Omega^+(v_k)$] is the set of all vertices incident to $v_k$.
	\item[$\Omega^-(v_k)$] is the set of all vertices incident from $v_k$.
	\item[Chain] is a sequence of arcs $u_1,u_2,\dots,u_q$ in which every intermediate arc $u_k$ has one vertex common with both previous $u_{k-1}$ and next $u_{k+1}$ vertices.
	\item[Cycle] is a chain in which no arc is used twice and first and last vertices have a common vertex.
	\item[Path] is a chain in which all arcs are directed in the same sense such that terminal vertex of preceeding arc is the initial vertex of the succeeding arc.
	\item[Circuit] is a cycle in which all arcs are directed in the same sense. 
	\item[Connected] A graph is connected if every pair of vertices have a chain connecting them. 
	\item[Component] is the set a vertex $v_a$ of all other vertices connetced to $v_a$ by chains.
	\item[Strongly Connected] A graph is strongly connected if there is a path connecting every pair of vertices in it.
	\item[Tree] is a connected graph with at least two verties and no cycles.
	\item[Centre] is a vertex which is connected to every other vertex of the graph by a path.
	\item[Arborescence] is a tree with a centre.
\end{description}

\subsection{Minimum Path Problem}
\begin{definition}[Minimum Path Problem]
	Let $x_{jk}$ be the real numbers associated to each arc $(v_j,v_k$. Let $v_a, v_b$ be two vertices of $G$. The length of a path from $v_a$ to $v_b$ is $\sum x_{jk}$ where the summation is over sequence of all arcs forming the path. The minimum path problem is to find the path of the smallest length among various path from $v_a$ to $v_b$.
\end{definition}

\begin{remark}
In general, $x_{jk}$ is unrestricted in sign.
\end{remark}

\subsubsection{All arc lengths are nonnegative}
\begin{commentary}
	The problem solved using an algorithm which is similar to proof by mathematical induction. 
	Initial step is trivial $V_0 = \{ v_a \}$. Hypothesis is that problem is solved for every vertex in $V_p$ for $p = k$. Our task is to find $V_{k+1}$ using $V_k$. The process is repeated till $v_b \in V_p$.
\end{commentary}

	Let $f_j$ be the length of the minimum path from $v_a$ to $v_j$. Then $f_a = 0$. And our goal is to find $f_b$.

\begin{commentary}
	Here, $p$ represents the stage. $V_p$ is the set of all vertices for which $f_j$ is known for every $v_j \in V_p$.
\end{commentary}

	$V_p$ is the set of all vertices for which minimum path problem is solved. The problem is solved when $v_b \in V_p$ for some $p$.

\begin{commentary}
	In each step, we find the vertex $v_s \notin V_p$ such that out of all the arcs leaving $V_p$, a particular arc incident on $v_s$ forms the minimum length path.
\end{commentary}

	$\Omega^-(V_p)$ is the set of all arcs going out a vertex in $V_p$ and let 
$$ f_r + x_{rs} = \min_{\Omega^-(V_p)} f_j + x_{jk} $$

\begin{commentary}
	This means that, we have found vertices $v_r \in V_p$, $v_s \notin V_p$ such that the arc $(v_r,v_s)$ forms the minimum length path leaving out of $V_p$ when it is combined with minimum length path to $v_r$ which is already known.
\end{commentary}

	Then, we repeat the process with $V_p = V_p \cup \{ v_s \}$ as $f_s = f_r + x_{rs}$ is the length of minimum path from $v_a$ to $v_s$.

	We start with $p = 0$, $V_0 = \{v_a\}$ and $f_a = 0$. Repeating the process we will get a sequence of sets $V_1,V_2,\dots$ if there is a set $V_k$ containing $v_b$ then minimum path length $f_b$ is found. If there is not such set in that sequence, then there is no path from $v_a$ to $v_b$.

\begin{example}
	Question : Find minimum path from $v_0$ to $v_8$ in the graph shown in figure \ref{dia:minPath1}. The number along the a directed arc denotes its length.

\begin{figure}
\centering
\begin{tikzpicture}
	\tikzset{arc/.style={postaction={decorate}, decoration={markings,mark=at position #1  with {\arrow{latex}}, }}}
	\begin{scope}
	\tikzstyle every node=[draw,circle]
	\draw (0,0) node(v0){$0$};
	\draw (2,2) node(v1){$1$};
	\draw (2,0) node(v2){$2$};
	\draw (2,-2) node(v3){$3$};
	\draw (6,2) node(v4){$4$};
	\draw (4,0) node(v5){$5$};
	\draw (6,-2) node(v6){$6$};
	\draw (8,1) node(v7){$7$};
	\draw (10,-1) node(v8){$8$};
	\end{scope}
	\draw[arc=0.5] (v0)--(v1) node (l1)[midway,label=above:$2$]{};
	\draw[arc=0.5] (v0)--(v2) node (l2)[midway,label=above:$6$]{};
	\draw[arc=0.5] (v0)--(v3) node (l3)[midway,label=above:$8$]{};
	\draw[arc=0.5] (v1)--(v4) node (l4)[midway,label=above:$10$]{};
	\draw[arc=0.5] (v1)--(v5) node (l5)[midway,label=above:$8$]{};
	\draw[arc=0.5] (v2)--(v5) node (l6)[midway,label=above:$1$]{};
	\draw[arc=0.5] (v3)--(v5) node (l7)[midway,label=above:$2$]{};
	\draw[arc=0.5] (v3)--(v6) node (l8)[midway,label=above:$4$]{};
	\draw[arc=0.5] (v4.30) to[out=20,in=100] (v7.90);
	\path (v4)--(v7) node(l9)[midway,label=above:$3$]{};
	\draw[arc=0.5] (v7.150) to[out=180,in=300] (v4.330);
	\path (v7)--(v4) node(l10)[midway,label=right:$2$]{};
	\draw[arc=0.5] (v5)--(v4) node (l11)[midway,label=above:$1$]{};
	\draw[arc=0.5] (v5)--(v7) node (l12)[midway,label=above:$5$]{};
	\draw[arc=0.5] (v6)--(v5) node (l13)[midway,label=above:$4$]{};
	\draw[arc=0.5] (v6.90) to[out=100,in=200] (v7.210);
	\path (v6)--(v7) node(l14)[midway,label=left:$6$]{};
	\draw[arc=0.5] (v7.270) to[out=280,in=20] (v6.30);
	\path (v7)--(v6) node(l15)[midway,label=right:$1$]{};
	\draw[arc=0.5] (v6)--(v8) node (l16)[midway,label=above:$7$]{};
	\draw[arc=0.5] (v7)--(v8) node (l17)[midway,label=above:$10$]{};
\end{tikzpicture}
\caption{Minimum Path Problem : Non-negative Arc Length}
\label{dia:minPath1}
\end{figure}

\begin{center}
\begin{tabular}{*{8}{c}}
	$p$ & $V_p$ & $f$ & $\Omega^-(V_p)$ & $x$ & $f+x$ & $f_s$ & $v_s$ \\ \hline
	0 & 0 & 0 & (0,1) & 2 & 2 & 2 & 1 \\
	& & & (0,2) & 6 & 6 & & \\
	& & & (0,3) & 8 & 8 & & \\ \hline
\end{tabular}
\end{center}

\begin{commentary}
	In Step 0, $p = 0$ and $V_p = \{ v_0 \}$. In column $V_p$, we wrote $0$ instead of $v_0$. And we know that, $f_0 = 0$. The arc incidents out of $v_0$ are $(0,1), (0,2), (0,3)$. These arcs are listed in column $\Omega^-(V_p)$. The arc length of $(0,1)$ is $x_{01} = 2$ which is wrote under the column $x$. In the first row, $f_j + x_{jk} = f_0 + x_{01}$, the sum is wrote under the column $f+x$.

	After completing all these columns, the least sum in column $f+x$ is seleted and wrote in the same row in column $f_s$ and the respective vertex is available in $\Omega^-(V_p)$ column in the same row as the second vertex of the arc. Here, it is $(0,1)$ and thus $v_s = 1$. Now Step 0 is complete and $V_p = \{ 0,1 \}$ as $v_s$ added to $V_p$. But, problem is not solved as $v_8 \notin V_p$. Thus we proceed to Step 1.
\end{commentary}

\begin{center}
\begin{tabular}{*{8}{c}}
	$p$ & $V_p$ & $f$ & $\Omega^-(V_p)$ & $x$ & $f+x$ & $f_s$ & $v_s$ \\ \hline
	1 & 0 & 0 & (0,2) & 6 & 6 & & \\
	& & & (0,3) & 8 & 8 & & \\
	& 1 & 2 & (1,2) & 3 & 5 & 5 & 2 \\
	& & & (1,4) & 10 & 12 & & \\
	& & & (1,5) & 8 & 10 & & \\ \hline
\end{tabular}
\end{center}

\begin{commentary}
	In Step 1, $p = 1$ and $V_p = \{v_0,v_1\}$. Each row of the table corresponds to each arc going out of $V_p$. There are two arcs incident from $v_0$ and three arcs incident from $v_1$.Thus there are two row for $v_0$ and three rows for $v_1$. Note that the arc $(0,1)$ is not considered as it has both end vertices in $V_p$.
	
	Then length of the arcs are wrote. It is added to the value in column $f$ and wrote in column $f+x$. The minimum value in column $f+x$ is selected. It corresponds to the arc $(1,2)$. Thus the vertex is $v_2$ and the length of minimum path from $v_0$ to $v_2$ is $5$.
\end{commentary}

Repeating the process a few more times, you will find that the minimum length path from $v_0$ to $v_8$ is $0,1,2,6,8$ and its length is $17$.(do it yourself)
\end{example}

\subsubsection{Arc lengths unrestricted in sign}
\pagebreak

%Module 4
\section{Non-linear Programming}

